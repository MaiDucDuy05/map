# Tourism Data Collection Pipeline

Pipeline thu tháº­p dá»¯ liá»‡u du lá»‹ch HÃ  Ná»™i tá»« nhiá»u nguá»“n cho RAG Chatbot.

##  TÃ­nh nÄƒng

-  **OpenStreetMap**: Láº¥y tá»a Ä‘á»™, tÃªn Ä‘á»‹a Ä‘iá»ƒm chÃ­nh xÃ¡c
- **Wikipedia**: ThÃªm thÃ´ng tin lá»‹ch sá»­, vÄƒn hÃ³a phong phÃº
- **Web Crawling**: Thu tháº­p tips, reviews tá»« web Travel
- **Cáº¥u trÃºc dá»¯ liá»‡u phÃ¢n táº§ng**: Tá»‘i Æ°u cho RAG
- **Metadata Ä‘áº§y Ä‘á»§**: Há»— trá»£ filtering vÃ  ranking

## CÃ i Ä‘áº·t

```bash
pip install -r requirements.txt --break-system-packages

# Hoáº·c vá»›i venv
python -m venv venv
source venv/bin/activate 
pip install -r requirements.txt
```

## Sá»­ dá»¥ng

### Cháº¡y full pipeline

```bash
python main.py
```

### Cháº¡y tá»«ng module riÃªng láº»

**1. Test OSM Collector:**
```bash
python osm_collector.py
```

**2. Test Wikipedia Enricher:**
```bash
python wikipedia_enricher.py
```

**3. Test Web Crawler:**
```bash
python web_crawler.py
```

**4. Test Data Processor:**
```bash
python data_processor.py
```

## ğŸ“Š Output

Dá»¯ liá»‡u sáº½ Ä‘Æ°á»£c lÆ°u trong thÆ° má»¥c `./hanoi_tourism_data/`:

```
hanoi_tourism_data/
â”œâ”€â”€ 01_osm_raw.json              # Dá»¯ liá»‡u thÃ´ tá»« OSM
â”œâ”€â”€ 02_wikipedia_enriched.json   # ÄÃ£ thÃªm Wikipedia
â”œâ”€â”€ 03_web_crawled.json          # ÄÃ£ thÃªm web data
â”œâ”€â”€ 04_final_rag_ready.json      # â˜… File cuá»‘i cÃ¹ng Ä‘á»ƒ dÃ¹ng cho RAG
â””â”€â”€ statistics.json              # Thá»‘ng kÃª
```

##  Cáº¥u trÃºc dá»¯ liá»‡u RAG

Má»—i Ä‘á»‹a Ä‘iá»ƒm cÃ³ cáº¥u trÃºc:

```json
{
  "id": "way_123456",
  "name": "VÄƒn Miáº¿u - Quá»‘c Tá»­ GiÃ¡m",
  "location": {
    "lat": 21.029,
    "lon": 105.835,
    "address": "..."
  },
  "layers": {
    "basic": {
      "category": "historic",
      "short_description": "..."
    },
    "historical": {
      "wikipedia_summary": "...",
      "significance": "...",
      "related_articles": [...]
    },
    "practical": {
      "opening_hours": "...",
      "tips": [...],
      "best_time_to_visit": "..."
    },
    "cultural": {
      "events": [...],
      "nearby_attractions": [...]
    }
  },
  "metadata": {
    "category": "historic",
    "has_wikipedia": true,
    "data_quality_score": 0.95,
    "tags": [...],
    "suitable_for": ["families", "students"]
  },
  "searchable_content": "Full text for search..."
}
```

## TÃ¹y chá»‰nh

### ThÃªm/bá»›t categories

Trong `main.py`, chá»‰nh sá»­a:

```python
categories = [
    "historic",
    "tourism", 
    "museum",
    # ThÃªm category khÃ¡c
]
```

### Thay Ä‘á»•i khu vá»±c

Trong `osm_collector.py`, chá»‰nh sá»­a `CITY_BOUNDS`:

```python
CITY_BOUNDS = {
    "Hanoi": {
        "south": 20.95,
        "north": 21.15,
        "west": 105.70,
        "east": 105.90
    },
 
}
```

### ThÃªm nguá»“n web khÃ¡c

Trong `web_crawler.py`, thÃªm vÃ o `SOURCES`:

```python
SOURCES = {
    "vnexpress_travel": {...},
    "your_source": {
        "base_url": "...",
        "enabled": True
    }
}
```

## Workflow Ä‘á» xuáº¥t

1. **Thu tháº­p dá»¯ liá»‡u** (cháº¡y 1 láº§n/thÃ¡ng):
   ```bash
   python main.py
   ```

2. **Import vÃ o Vector DB** (Chroma/Qdrant/...):
   ```python
   import json
   
   with open('hanoi_tourism_data/04_final_rag_ready.json') as f:
       documents = json.load(f)
   
   for doc in documents:
       text = doc['searchable_content']
       embedding = embed_function(text)
       vector_db.add(embedding, metadata=doc)
   ```

3. **Sá»­ dá»¥ng trong RAG Chatbot**:
   ```python
   query = "Äá»‹a Ä‘iá»ƒm lá»‹ch sá»­ nÃ o á»Ÿ HÃ  Ná»™i phÃ¹ há»£p cho gia Ä‘Ã¬nh?"
   
   results = vector_db.search(query, k=3, 
       filter={"suitable_for": "families"})
   
   # Generate answer vá»›i LLM
   context = "\n\n".join([r['searchable_content'] for r in results])
   answer = llm.generate(query, context)
   ```

## Cáº£i thiá»‡n cháº¥t lÆ°á»£ng

### TÄƒng Ä‘á»™ phá»§
- Má»Ÿ rá»™ng bounding box trong `CITY_BOUNDS`
- ThÃªm nhiá»u categories trong OSM query
- Crawl thÃªm nhiá»u website

### TÄƒng Ä‘á»™ chÃ­nh xÃ¡c
- Verify thÃ´ng tin chÃ©o giá»¯a cÃ¡c nguá»“n
- ThÃªm manual review cho POI quan trá»ng
- Cáº­p nháº­t Ä‘á»‹nh ká»³

### Tá»‘i Æ°u RAG
- Embed tá»«ng layer riÃªng Ä‘á»ƒ search chÃ­nh xÃ¡c hÆ¡n
- DÃ¹ng hybrid search (semantic + keyword)
- Implement reranking vá»›i cross-encoder

## Xá»­ lÃ½ lá»—i thÆ°á»ng gáº·p

**1. Overpass API timeout:**
- Script tá»± Ä‘á»™ng retry vá»›i cÃ¡c server khÃ¡c
- Náº¿u váº«n lá»—i, giáº£m kÃ­ch thÆ°á»›c bounding box

**2. Wikipedia khÃ´ng tÃ¬m tháº¥y:**
- BÃ¬nh thÆ°á»ng, khÃ´ng pháº£i táº¥t cáº£ Ä‘á»‹a Ä‘iá»ƒm Ä‘á»u cÃ³ trÃªn Wikipedia
- Script sáº½ bá» qua vÃ  tiáº¿p tá»¥c

**3. Web crawler bá»‹ block:**
- Script cÃ³ rate limiting (2s/request)
- Náº¿u váº«n bá»‹ block, tÄƒng delay trong `web_crawler.py`

## Logs

Check file `data_collection.log` Ä‘á»ƒ xem chi tiáº¿t quÃ¡ trÃ¬nh cháº¡y.

