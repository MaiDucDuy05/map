// langchain/agent/nodes.ts
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";
import { GoogleGenerativeAIEmbeddings } from "@langchain/google-genai";
import { Chroma } from "@langchain/community/vectorstores/chroma";
import { Document } from "@langchain/core/documents";
import { SystemMessage } from "@langchain/core/messages";
import { AgentStateType } from "./state";
import { allTools } from "./tools";
import { extractAllLocations } from "../utils/extractors";
import { END } from "@langchain/langgraph";

let vectorStoreInstance: Chroma | null = null;
let isVectorStoreInitialized = false;

async function getVectorStore(): Promise<Chroma> {
  if (!vectorStoreInstance || !isVectorStoreInitialized) {
    
    const embeddings = new GoogleGenerativeAIEmbeddings({
      model: "models/gemini-embedding-001",
      apiKey: process.env.GOOGLE_API_KEY,
    });

    vectorStoreInstance = await Chroma.fromExistingCollection(embeddings, {
      collectionName: "langchain",
      url: process.env.CHROMA_URL,
      collectionMetadata: {
        "hnsw:space": "l2",
      },
    });

    isVectorStoreInitialized = true;
    console.log("Vector Store initialized");
  }

  return vectorStoreInstance;
}


// ===== NODE 1: ROUTER =====
export async function routerNode(state: AgentStateType) {
  const lastMessage = state.messages[state.messages.length - 1];
  const query = lastMessage.content as string;

  console.log("Router analyzing query...");

  const llm = new ChatGoogleGenerativeAI({
    model: "models/gemini-2.5-flash-preview-tts",
    temperature: 0, 
    maxOutputTokens: 10,
    apiKey: process.env.GOOGLE_API_KEY,
  });

  const routerPrompt = `Báº¡n lÃ  má»™t bá»™ phÃ¢n loáº¡i cÃ¢u há»i du lá»‹ch HÃ  Ná»™i.

Nhiá»‡m vá»¥: XÃ¡c Ä‘á»‹nh cÃ¢u há»i cÃ³ cáº§n tra cá»©u cÆ¡ sá»Ÿ dá»¯ liá»‡u Ä‘á»‹a Ä‘iá»ƒm khÃ´ng.

Tráº£ lá»i "YES" náº¿u cÃ¢u há»i:
- Há»i vá» Ä‘á»‹a Ä‘iá»ƒm, quÃ¡n Äƒn, nhÃ  hÃ ng, cafe cá»¥ thá»ƒ
- Há»i vá» Ä‘á»‹a chá»‰, giá» má»Ÿ cá»­a, giÃ¡ vÃ©
- Há»i vá» gá»£i Ã½ tham quan, Äƒn uá»‘ng
- Há»i vá» Ä‘Æ°á»ng Ä‘i, cÃ¡ch di chuyá»ƒn
- Há»i vá» lá»‹ch trÃ¬nh du lá»‹ch

Tráº£ lá»i "NO" náº¿u cÃ¢u há»i:
- ChÃ o há»i thÃ´ng thÆ°á»ng (xin chÃ o, hi, hello...)
- Há»i vá» báº¡n lÃ  ai
- CÃ¢u há»i khÃ´ng liÃªn quan Ä‘áº¿n Ä‘á»‹a Ä‘iá»ƒm du lá»‹ch
- Cáº£m Æ¡n, táº¡m biá»‡t

CÃ¢u há»i: "${query}"

Chá»‰ tráº£ lá»i YES hoáº·c NO:`;

  try {
    const response = await llm.invoke(routerPrompt);
    const decision = (response.content as string).trim().toUpperCase();
    const needsRetrieval = decision.includes("YES");

    console.log(`Router decision: ${decision} â†’ needsRetrieval = ${needsRetrieval}`);

    return {
      query,
      needsRetrieval,
    };
  } catch (error) {
    console.error("Router LLM error, fallback to regex:", error);

    const needsRetrieval = 
      /Ä‘á»‹a Ä‘iá»ƒm|quÃ¡n|nhÃ  hÃ ng|chÃ¹a|Ä‘á»n|báº£o tÃ ng|há»“|phá»‘|cafe|Äƒn uá»‘ng|tham quan|du lá»‹ch/i.test(query) ||
      /nÃ o|Ä‘Ã¢u|gÃ¬|nhÆ° tháº¿ nÃ o|lÃ m sao|á»Ÿ Ä‘Ã¢u|gáº§n/i.test(query);

    return {
      query,
      needsRetrieval,
    };
  }
}

// ===== NODE 2: RETRIEVAL =====
export async function retrievalNode(state: AgentStateType) {
  if (!state.needsRetrieval) {
    console.log("Skipping retrieval");
    return { retrievedDocs: [], extractedLocations: [] };
  }

  try {
    const vectorStore = await getVectorStore();
    const retriever = vectorStore.asRetriever({
      k: 3,
      searchType: "similarity",
    });

    const contextDocs = await retriever.invoke(state.query); 
    
    const extractedLocations = extractAllLocations(contextDocs);

    
    return { 
      retrievedDocs: contextDocs,
      extractedLocations,
    };
  } catch (error: any) {
    console.error("Retrieval error:", error);
    return { 
      retrievedDocs: [], 
      extractedLocations: [] 
    };
  }
}

// ===== NODE 3: AGENT LLM =====
export async function agentNode(state: AgentStateType) {
  console.log("Agent processing...");
  const llm = new ChatGoogleGenerativeAI({
    model: "models/gemini-flash-lite-latest",
    temperature: 0.3,
    maxOutputTokens: 2048, 
    apiKey: process.env.GOOGLE_API_KEY,
  });

  const llmWithTools = llm.bindTools(allTools);

  const formatDocs = (docs: Document[]) => {
    return docs
      .map((doc, i) => `[TÃ i liá»‡u ${i + 1}]\n${doc.pageContent}`)
      .join("\n\n");
  };

  let contextStr = "";
  
  if (state.retrievedDocs && state.retrievedDocs.length > 0) {
    const formattedContext = formatDocs(state.retrievedDocs);
    contextStr = `\n\nNgá»¯ cáº£nh (ThÃ´ng tin tÃ¬m Ä‘Æ°á»£c):\n${formattedContext}`;
  }

  if (state.conversationContext) {
    contextStr = `\n\nCuá»™c há»™i thoáº¡i trÆ°á»›c:\n${state.conversationContext}` + contextStr;
  }

  if (state.userPreferences && Object.keys(state.userPreferences).length > 0) {
    contextStr += `\n\nSá»Ÿ thÃ­ch ngÆ°á»i dÃ¹ng: ${JSON.stringify(state.userPreferences)}`;
  }

  const systemMessage = new SystemMessage(`Báº¡n lÃ  má»™t hÆ°á»›ng dáº«n viÃªn du lá»‹ch HÃ  Ná»™i thÃ¢n thiá»‡n vÃ  am hiá»ƒu.

HÃ£y sá»­ dá»¥ng thÃ´ng tin ngá»¯ cáº£nh dÆ°á»›i Ä‘Ã¢y Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng.

**NguyÃªn táº¯c tráº£ lá»i:**
- Náº¿u thÃ´ng tin khÃ´ng cÃ³ trong ngá»¯ cáº£nh, hÃ£y nÃ³i tháº­t lÃ  báº¡n khÃ´ng biáº¿t, Ä‘á»«ng cá»‘ bá»‹a ra.
- CÃ¢u tráº£ lá»i cáº§n ngáº¯n gá»n, xÃºc tÃ­ch nhÆ°ng Ä‘áº§y Ä‘á»§ thÃ´ng tin (Ä‘á»‹a chá»‰, giÃ¡ vÃ©, tips náº¿u cÃ³).
- Tráº£ lá»i báº±ng Markdown format: sá»­ dá»¥ng headings (##), lists, **bold** Ä‘á»ƒ dá»… Ä‘á»c.

**CÃ´ng cá»¥ kháº£ dá»¥ng:**
1. vector_search - TÃ¬m kiáº¿m thÃªm thÃ´ng tin vá» Ä‘á»‹a Ä‘iá»ƒm
2. mongo_search - TÃ¬m lá»‹ch sá»­ ngÆ°á»i dÃ¹ng
3. get_user_preferences - Láº¥y sá»Ÿ thÃ­ch ngÆ°á»i dÃ¹ng
4. add_map_marker - ThÃªm marker lÃªn báº£n Ä‘á»“
5. navigate_map - Äiá»u hÆ°á»›ng báº£n Ä‘á»“ Ä‘áº¿n vá»‹ trÃ­
6. create_route - Táº¡o Ä‘Æ°á»ng Ä‘i giá»¯a 2 Ä‘iá»ƒm
7. save_location_mention - LÆ°u Ä‘á»‹a Ä‘iá»ƒm vÃ o lá»‹ch sá»­

**HÃ nh Ä‘á»™ng tá»± Ä‘á»™ng:**
- Khi cÃ³ tá»a Ä‘á»™, hÃ£y tá»± Ä‘á»™ng navigate hoáº·c thÃªm marker Ä‘á»ƒ ngÆ°á»i dÃ¹ng dá»… xem
- Khi gá»£i Ã½ nhiá»u Ä‘á»‹a Ä‘iá»ƒm, add markers cho táº¥t cáº£
- LuÃ´n thÃ¢n thiá»‡n, nhiá»‡t tÃ¬nh báº±ng tiáº¿ng Viá»‡t

${contextStr}`);
  const response = await llmWithTools.invoke([
    systemMessage,
    ...state.messages,
  ]);

  console.log(` Agent response generated`);

  return {
    messages: [response],
  };
}

// ===== NODE 4: EXTRACT MAP ACTIONS =====
export async function extractMapActionsNode(state: AgentStateType) {
  const lastMessage = state.messages[state.messages.length - 1];
  const mapActions: any[] = [];

  if (lastMessage && 'tool_calls' in lastMessage && lastMessage.tool_calls) {
    for (const toolCall of lastMessage.tool_calls) {
      if (['add_map_marker', 'navigate_map', 'create_route'].includes(toolCall.name)) {
        mapActions.push({
          type: toolCall.name,
          args: toolCall.args,
        });
      }
    }
    
    console.log(`ğŸ“ Extracted ${mapActions.length} map actions`);
  }

  return { mapActions };
}

// ===== CONDITIONAL EDGES =====
export function shouldContinue(state: AgentStateType) {
  const lastMessage = state.messages[state.messages.length - 1];
  
  if (lastMessage && 'tool_calls' in lastMessage && lastMessage.tool_calls?.length) {
    console.log(`ğŸ”§ Routing to tools (${lastMessage.tool_calls.length} calls)`);
    return "tools";
  }
  
  console.log("âœ… Ending workflow");
  return END;
}

export function shouldRetrieve(state: AgentStateType) {
  return state.needsRetrieval ? "retrieval" : "agent";
}